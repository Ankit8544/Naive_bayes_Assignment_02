{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Q.No-01`    A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans :-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To solve this problem, we need to use the concept of conditional probability and Bayes' theorem.**\n",
    "\n",
    "**`Given information` -**\n",
    "\n",
    "$$P(uses ~health ~insurance ~plan) ~~or ~~P(A)  = 0.7 $$ \n",
    "\n",
    "$$P(smoker|uses ~health ~insurance ~plan) ~~or ~~P(B|A)  = 0.4 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have to find** $P(B|A)$ **which is alreadt given,**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(B|A) = 0.4 \\quad \\text{or} \\quad 40\\% $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**40% is the probability that an employee is a smoker given that he/she uses the health insurance plan**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Q.No-02`    What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans :-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Both Bernoulli Naive Bayes and Multinomial Naive Bayes are types of Naive Bayes classifiers, a popular machine learning method based on Bayes' theorem.**\n",
    "\n",
    "**They share the core principle of assuming independence between features, but differ in how they `handle the features` themselves -**\n",
    "\n",
    "* **Bernoulli Naive Bayes :** This is suited for **binary features**, meaning each feature can only take on two values, typically represented as presence (1) or absence (0) of a specific characteristic. For example, an email can be classified as spam (1) or not spam (0). Here, the model considers how often a particular word appears (presence) or doesn't appear (absence) in spam emails compared to non-spam emails.\n",
    "\n",
    "* **Multinomial Naive Bayes :** This is designed for features with **discrete counts**. Here, a feature can have multiple values, but each value represents a count or frequency. A common application is text classification. Each word in a document is considered a feature, and its value is the number of times it appears in that document. The model then analyzes how frequently each word shows up in different categories (e.g., sports news vs. entertainment news).\n",
    "\n",
    "**`In simpler terms`, Bernoulli Naive Bayes cares about \"yes\" or \"no\" for a feature, while Multinomial Naive Bayes cares about \"how many times\" for a feature.**\n",
    "\n",
    "**Here's a table `summarizing the key differences` -**\n",
    "\n",
    "| Feature Type | Naive Bayes Variant | Description |\n",
    "|---|---|---|\n",
    "| Binary | Bernoulli | Focuses on presence (1) or absence (0) of a feature |\n",
    "| Discrete Counts | Multinomial | Analyzes the number of times a feature appears |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Q.No-03`    How does Bernoulli Naive Bayes handle missing values?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans :-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bernoulli Naive Bayes, a type of Naive Bayes classifier for binary features, doesn't have a built-in way to handle missing values directly. This can be problematic because the algorithm relies on probabilities calculated from feature values, and missing data can skew these calculations.**\n",
    "\n",
    "**Here are some common approaches to address missing values before using Bernoulli Naive Bayes :**\n",
    "\n",
    "1. **Dropping Data Points -** The simplest method is to remove any data points containing missing values.  This can be a good option if the amount of missing data is small. However, it can also lead to a loss of information, potentially affecting the model's performance.\n",
    "\n",
    "2. **Imputation -** Another approach is to impute missing values. This involves estimating a value to fill in the missing spot. There are various imputation techniques, like replacing missing values with the mean/median of the feature or using more sophisticated methods.\n",
    "\n",
    "3. **Ignoring the Feature -** When a data point has a missing value, you can choose to ignore that specific feature for that particular data point. This essentially treats the missing value as its own category and adjusts the probability calculations accordingly.\n",
    "\n",
    "`While scikit-learn's BernoulliNB model doesn't directly handle missing values`, **We can implement these strategies before feeding your data to the model. There are also libraries offering alternative Naive Bayes implementations that might have built-in missing value handling capabilities.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Q.No-04`    Can Gaussian Naive Bayes be used for multi-class classification?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans :-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Yes, Gaussian Naive Bayes (GNB) can indeed be used for multi-class classification tasks`. Despite its \"naive\" assumption of feature independence, which may not always hold true in practice, GNB is still commonly employed for its simplicity and efficiency, especially when dealing with relatively small datasets.**\n",
    "\n",
    "For multi-class classification, GNB extends naturally by applying the Bayes' theorem to calculate the probability of each class given the input features and then selecting the class with the highest probability. This approach works by assuming that the features follow a Gaussian distribution within each class, hence the name \"Gaussian\" Naive Bayes.\n",
    "\n",
    "`However`, it's worth noting that GNB might not perform optimally compared to more complex models like Support Vector Machines, Random Forests, or deep learning models, especially when dealing with highly correlated features or complex relationships within the data. Nonetheless, it can still serve as a baseline model or be used in scenarios where computational efficiency and simplicity are crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Q.No-05`    Assignment :-**\n",
    "\n",
    "-    **Data preparation :** Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message is spam or not based on several input features.\n",
    "\n",
    "\n",
    "-    **Implementation :** Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "dataset. You should use the default hyperparameters for each classifier.\n",
    "\n",
    "\n",
    "-    **Results :** Report the following performance metrics for each classifier -\n",
    "\n",
    "        -    Accuracy\n",
    "\n",
    "        -    Precision\n",
    "\n",
    "        -    Recall\n",
    "\n",
    "        -    F1 score\n",
    "\n",
    "\n",
    "-    **Discussion :** Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is the case? Are there any limitations of Naive Bayes that you observed?\n",
    "\n",
    "\n",
    "-    **Conclusion :** Summarise your findings and provide some suggestions for future work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans :-**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# fetch dataset \n",
    "spambase = fetch_ucirepo(id=94) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data (as pandas dataframes) \n",
    "X = spambase.data.features \n",
    "y = (spambase.data.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uci_id': 94,\n",
       " 'name': 'Spambase',\n",
       " 'repository_url': 'https://archive.ics.uci.edu/dataset/94/spambase',\n",
       " 'data_url': 'https://archive.ics.uci.edu/static/public/94/data.csv',\n",
       " 'abstract': 'Classifying Email as Spam or Non-Spam',\n",
       " 'area': 'Computer Science',\n",
       " 'tasks': ['Classification'],\n",
       " 'characteristics': ['Multivariate'],\n",
       " 'num_instances': 4601,\n",
       " 'num_features': 57,\n",
       " 'feature_types': ['Integer', 'Real'],\n",
       " 'demographics': [],\n",
       " 'target_col': ['Class'],\n",
       " 'index_col': None,\n",
       " 'has_missing_values': 'no',\n",
       " 'missing_values_symbol': None,\n",
       " 'year_of_dataset_creation': 1999,\n",
       " 'last_updated': 'Mon Aug 28 2023',\n",
       " 'dataset_doi': '10.24432/C53G6X',\n",
       " 'creators': ['Mark Hopkins',\n",
       "  'Erik Reeber',\n",
       "  'George Forman',\n",
       "  'Jaap Suermondt'],\n",
       " 'intro_paper': None,\n",
       " 'additional_info': {'summary': 'The \"spam\" concept is diverse: advertisements for products/web sites, make money fast schemes, chain letters, pornography...\\n\\nThe classification task for this dataset is to determine whether a given email is spam or not.\\n\\t\\nOur collection of spam e-mails came from our postmaster and individuals who had filed spam.  Our collection of non-spam e-mails came from filed work and personal e-mails, and hence the word \\'george\\' and the area code \\'650\\' are indicators of non-spam.  These are useful when constructing a personalized spam filter.  One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter.\\n\\nFor background on spam: Cranor, Lorrie F., LaMacchia, Brian A.  Spam!, Communications of the ACM, 41(8):74-83, 1998.\\n\\nTypical performance is around ~7% misclassification error. False positives (marking good mail as spam) are very undesirable.If we insist on zero false positives in the training/testing set, 20-25% of the spam passed through the filter. See also Hewlett-Packard Internal-only Technical Report. External version forthcoming. ',\n",
       "  'purpose': None,\n",
       "  'funded_by': None,\n",
       "  'instances_represent': 'Emails',\n",
       "  'recommended_data_splits': None,\n",
       "  'sensitive_data': None,\n",
       "  'preprocessing_description': None,\n",
       "  'variable_info': 'The last column of \\'spambase.data\\' denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail.  The run-length attributes (55-57) measure the length of sequences of consecutive capital letters.  For the statistical measures of each attribute, see the end of this file.  Here are the definitions of the attributes:\\r\\n\\r\\n48 continuous real [0,100] attributes of type word_freq_WORD \\r\\n= percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail.  A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string.\\r\\n\\r\\n6 continuous real [0,100] attributes of type char_freq_CHAR] \\r\\n= percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail\\r\\n\\r\\n1 continuous real [1,...] attribute of type capital_run_length_average \\r\\n= average length of uninterrupted sequences of capital letters\\r\\n\\r\\n1 continuous integer [1,...] attribute of type capital_run_length_longest \\r\\n= length of longest uninterrupted sequence of capital letters\\r\\n\\r\\n1 continuous integer [1,...] attribute of type capital_run_length_total \\r\\n= sum of length of uninterrupted sequences of capital letters \\r\\n= total number of capital letters in the e-mail\\r\\n\\r\\n1 nominal {0,1} class attribute of type spam\\r\\n= denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  \\r\\n',\n",
       "  'citation': None}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# metadata \n",
    "display(spambase.metadata) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>role</th>\n",
       "      <th>type</th>\n",
       "      <th>demographic</th>\n",
       "      <th>description</th>\n",
       "      <th>units</th>\n",
       "      <th>missing_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word_freq_make</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word_freq_address</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>word_freq_all</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>word_freq_3d</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>word_freq_our</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>word_freq_over</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>word_freq_remove</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>word_freq_internet</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>word_freq_order</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>word_freq_mail</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>word_freq_receive</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>word_freq_will</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>word_freq_people</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>word_freq_report</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>word_freq_addresses</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>word_freq_free</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>word_freq_business</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>word_freq_email</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>word_freq_you</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>word_freq_credit</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>word_freq_your</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>word_freq_font</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>word_freq_000</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>word_freq_money</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>word_freq_hp</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>word_freq_hpl</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>word_freq_george</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>word_freq_650</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>word_freq_lab</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>word_freq_labs</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>word_freq_telnet</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>word_freq_857</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>word_freq_data</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>word_freq_415</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>word_freq_85</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>word_freq_technology</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>word_freq_1999</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>word_freq_parts</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>word_freq_pm</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>word_freq_direct</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>word_freq_cs</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>word_freq_meeting</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>word_freq_original</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>word_freq_project</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>word_freq_re</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>word_freq_edu</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>word_freq_table</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>word_freq_conference</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>char_freq_;</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>char_freq_(</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>char_freq_[</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>char_freq_!</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>char_freq_$</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>char_freq_#</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>capital_run_length_average</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>capital_run_length_longest</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>capital_run_length_total</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Class</td>\n",
       "      <td>Target</td>\n",
       "      <td>Binary</td>\n",
       "      <td>None</td>\n",
       "      <td>spam (1) or not spam (0)</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name     role        type demographic  \\\n",
       "0               word_freq_make  Feature  Continuous        None   \n",
       "1            word_freq_address  Feature  Continuous        None   \n",
       "2                word_freq_all  Feature  Continuous        None   \n",
       "3                 word_freq_3d  Feature  Continuous        None   \n",
       "4                word_freq_our  Feature  Continuous        None   \n",
       "5               word_freq_over  Feature  Continuous        None   \n",
       "6             word_freq_remove  Feature  Continuous        None   \n",
       "7           word_freq_internet  Feature  Continuous        None   \n",
       "8              word_freq_order  Feature  Continuous        None   \n",
       "9               word_freq_mail  Feature  Continuous        None   \n",
       "10           word_freq_receive  Feature  Continuous        None   \n",
       "11              word_freq_will  Feature  Continuous        None   \n",
       "12            word_freq_people  Feature  Continuous        None   \n",
       "13            word_freq_report  Feature  Continuous        None   \n",
       "14         word_freq_addresses  Feature  Continuous        None   \n",
       "15              word_freq_free  Feature  Continuous        None   \n",
       "16          word_freq_business  Feature  Continuous        None   \n",
       "17             word_freq_email  Feature  Continuous        None   \n",
       "18               word_freq_you  Feature  Continuous        None   \n",
       "19            word_freq_credit  Feature  Continuous        None   \n",
       "20              word_freq_your  Feature  Continuous        None   \n",
       "21              word_freq_font  Feature  Continuous        None   \n",
       "22               word_freq_000  Feature  Continuous        None   \n",
       "23             word_freq_money  Feature  Continuous        None   \n",
       "24                word_freq_hp  Feature  Continuous        None   \n",
       "25               word_freq_hpl  Feature  Continuous        None   \n",
       "26            word_freq_george  Feature  Continuous        None   \n",
       "27               word_freq_650  Feature  Continuous        None   \n",
       "28               word_freq_lab  Feature  Continuous        None   \n",
       "29              word_freq_labs  Feature  Continuous        None   \n",
       "30            word_freq_telnet  Feature  Continuous        None   \n",
       "31               word_freq_857  Feature  Continuous        None   \n",
       "32              word_freq_data  Feature  Continuous        None   \n",
       "33               word_freq_415  Feature  Continuous        None   \n",
       "34                word_freq_85  Feature  Continuous        None   \n",
       "35        word_freq_technology  Feature  Continuous        None   \n",
       "36              word_freq_1999  Feature  Continuous        None   \n",
       "37             word_freq_parts  Feature  Continuous        None   \n",
       "38                word_freq_pm  Feature  Continuous        None   \n",
       "39            word_freq_direct  Feature  Continuous        None   \n",
       "40                word_freq_cs  Feature  Continuous        None   \n",
       "41           word_freq_meeting  Feature  Continuous        None   \n",
       "42          word_freq_original  Feature  Continuous        None   \n",
       "43           word_freq_project  Feature  Continuous        None   \n",
       "44                word_freq_re  Feature  Continuous        None   \n",
       "45               word_freq_edu  Feature  Continuous        None   \n",
       "46             word_freq_table  Feature  Continuous        None   \n",
       "47        word_freq_conference  Feature  Continuous        None   \n",
       "48                 char_freq_;  Feature  Continuous        None   \n",
       "49                 char_freq_(  Feature  Continuous        None   \n",
       "50                 char_freq_[  Feature  Continuous        None   \n",
       "51                 char_freq_!  Feature  Continuous        None   \n",
       "52                 char_freq_$  Feature  Continuous        None   \n",
       "53                 char_freq_#  Feature  Continuous        None   \n",
       "54  capital_run_length_average  Feature  Continuous        None   \n",
       "55  capital_run_length_longest  Feature  Continuous        None   \n",
       "56    capital_run_length_total  Feature  Continuous        None   \n",
       "57                       Class   Target      Binary        None   \n",
       "\n",
       "                 description units missing_values  \n",
       "0                       None  None             no  \n",
       "1                       None  None             no  \n",
       "2                       None  None             no  \n",
       "3                       None  None             no  \n",
       "4                       None  None             no  \n",
       "5                       None  None             no  \n",
       "6                       None  None             no  \n",
       "7                       None  None             no  \n",
       "8                       None  None             no  \n",
       "9                       None  None             no  \n",
       "10                      None  None             no  \n",
       "11                      None  None             no  \n",
       "12                      None  None             no  \n",
       "13                      None  None             no  \n",
       "14                      None  None             no  \n",
       "15                      None  None             no  \n",
       "16                      None  None             no  \n",
       "17                      None  None             no  \n",
       "18                      None  None             no  \n",
       "19                      None  None             no  \n",
       "20                      None  None             no  \n",
       "21                      None  None             no  \n",
       "22                      None  None             no  \n",
       "23                      None  None             no  \n",
       "24                      None  None             no  \n",
       "25                      None  None             no  \n",
       "26                      None  None             no  \n",
       "27                      None  None             no  \n",
       "28                      None  None             no  \n",
       "29                      None  None             no  \n",
       "30                      None  None             no  \n",
       "31                      None  None             no  \n",
       "32                      None  None             no  \n",
       "33                      None  None             no  \n",
       "34                      None  None             no  \n",
       "35                      None  None             no  \n",
       "36                      None  None             no  \n",
       "37                      None  None             no  \n",
       "38                      None  None             no  \n",
       "39                      None  None             no  \n",
       "40                      None  None             no  \n",
       "41                      None  None             no  \n",
       "42                      None  None             no  \n",
       "43                      None  None             no  \n",
       "44                      None  None             no  \n",
       "45                      None  None             no  \n",
       "46                      None  None             no  \n",
       "47                      None  None             no  \n",
       "48                      None  None             no  \n",
       "49                      None  None             no  \n",
       "50                      None  None             no  \n",
       "51                      None  None             no  \n",
       "52                      None  None             no  \n",
       "53                      None  None             no  \n",
       "54                      None  None             no  \n",
       "55                      None  None             no  \n",
       "56                      None  None             no  \n",
       "57  spam (1) or not spam (0)  None             no  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# variable information \n",
    "display(spambase.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bernoulli NB</th>\n",
       "      <th>Multinomial NB</th>\n",
       "      <th>Gaussian NB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.883938</td>\n",
       "      <td>0.786350</td>\n",
       "      <td>0.821773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.886962</td>\n",
       "      <td>0.739318</td>\n",
       "      <td>0.710373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.815239</td>\n",
       "      <td>0.721498</td>\n",
       "      <td>0.956952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.848125</td>\n",
       "      <td>0.728291</td>\n",
       "      <td>0.813066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Bernoulli NB  Multinomial NB  Gaussian NB\n",
       "accuracy       0.883938        0.786350     0.821773\n",
       "precision      0.886962        0.739318     0.710373\n",
       "recall         0.815239        0.721498     0.956952\n",
       "f1             0.848125        0.728291     0.813066"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialize classifiers\n",
    "bnb = BernoulliNB()\n",
    "mnb = MultinomialNB()\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Perform 10-fold cross-validation and compute performance metrics\n",
    "classifiers = {'Bernoulli NB': bnb, 'Multinomial NB': mnb, 'Gaussian NB': gnb}\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    scores = {}\n",
    "    for metric in metrics:\n",
    "        score = cross_val_score(clf, X, y, cv=10, scoring=metric)\n",
    "        scores[metric] = score.mean()\n",
    "    results[name] = scores\n",
    "    \n",
    "results_df = pd.DataFrame(results, index=metrics)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Based on the outcome of the performance metrics, we can Discuss about the following trends` :**\n",
    "\n",
    "1. **Accuracy -** Bernoulli Naive Bayes achieved the highest accuracy among the three variants, followed by Gaussian Naive Bayes and Multinomial Naive Bayes.\n",
    "\n",
    "2. **Precision -** Bernoulli Naive Bayes also exhibited the highest precision, followed by Gaussian Naive Bayes and Multinomial Naive Bayes.\n",
    "\n",
    "3. **Recall -** Gaussian Naive Bayes had the highest recall, followed by Bernoulli Naive Bayes and Multinomial Naive Bayes.\n",
    "\n",
    "4. **F1 Score -** Bernoulli Naive Bayes showed the highest F1 score, followed by Gaussian Naive Bayes and Multinomial Naive Bayes.\n",
    "\n",
    "These results indicate that for this Spambase dataset, Bernoulli Naive Bayes generally outperformed the other variants in terms of accuracy, precision, and F1 score. However, Gaussian Naive Bayes performed notably well in terms of recall.\n",
    "\n",
    "`The reason behind Bernoulli Naive Bayes' superior performance could be attributed to its assumption of binary features`, which might be well-suited for the nature of the input features in the dataset. Since the Spambase dataset consists of binary features indicating the presence or absence of certain words or characters in email messages, Bernoulli Naive Bayes, which assumes binary features, might be more appropriate for this type of data.\n",
    "\n",
    "`On the other hand`, Multinomial Naive Bayes assumes integer counts as features and might not be the best choice for binary data like in the Spambase dataset. Gaussian Naive Bayes assumes a Gaussian distribution for numerical features, which might not be the most suitable assumption for this dataset, although it performed surprisingly well in terms of recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`In conclusion based on the evaluation results`, **Bernoulli Naive Bayes appears to be the most suitable variant for the task of classifying spam emails in the Spambase dataset. Its superior performance in terms of accuracy, precision, and F1 score suggests its effectiveness in handling binary feature data such as email content.**\n",
    "\n",
    "However, it's worth noting that Gaussian Naive Bayes showed remarkable performance in terms of recall, indicating its potential usefulness in capturing spam instances effectively, albeit with some trade-offs in other performance metrics.\n",
    "\n",
    "Future work could involve exploring feature engineering techniques to enhance the performance of Naive Bayes classifiers further. Additionally, experimenting with other classification algorithms and ensemble methods could provide insights into whether alternative approaches could yield even better results for spam classification tasks. Moreover, investigating the impact of different hyperparameters and preprocessing techniques could also be valuable for improving classification performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
